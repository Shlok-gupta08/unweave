<p align="center">
  <img src="frontend/public/logo.png" alt="Unweave Logo" width="180" />
</p>

<h1 align="center">Unweave</h1>

<p align="center">
  <strong>Visualize the layers. Isolate the sound.</strong>
</p>

<p align="center">
  <a href="#-quick-start"><img src="https://img.shields.io/badge/Quick_Start-blue?style=for-the-badge" alt="Quick Start"></a>
  <a href="LICENSE"><img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="MIT License"></a>
  <a href="#-gpu-support"><img src="https://img.shields.io/badge/GPU-Accelerated-orange?style=for-the-badge" alt="GPU Accelerated"></a>
  <a href="docs/cloud-guide.html"><img src="https://img.shields.io/badge/Cloud-Ready-purple?style=for-the-badge" alt="Cloud Ready"></a>
</p>

<p align="center">
  Upload any audio track and instantly isolate <strong>Vocals, Drums, Bass, Guitar, Piano & Other</strong>.<br/>
  Studio-grade 6-stem separation powered by AI.
</p>

---

## âœ¨ Features

### AI Separation Engine
- ğŸ§  **6-Stem AI Separation** â€” Powered by `htdemucs_6s` (Hybrid Transformer Demucs) for studio-grade isolation of Vocals, Drums, Bass, Guitar, Piano, and Other
- âš¡ **Multi-GPU Support** â€” NVIDIA CUDA, Apple Silicon MPS, AMD ROCm/DirectML, and CPU fallback
- ğŸ“Š **Real-Time Progress** â€” Live progress bar with ETA, powered by tqdm parsing from a subprocess worker
- ğŸ”„ **Background Processing** â€” Separation runs in a subprocess so the API stays responsive
- ğŸ›‘ **Cancel Anytime** â€” Instantly terminate a running separation job with process-level cancellation

### Interactive Mixer
- ğŸµ **Play / Pause All** â€” Global transport control that plays or pauses all tracks in perfect sync without altering mute states
- ğŸ§ **Solo Play** â€” Click the play button on any individual track to solo it (mutes all others and starts synced playback)
- ğŸ”‡ **Mute / Unmute** â€” Toggle mute on individual tracks; muted tracks stay silent even during global play
- ğŸ”Š **Unmute All** â€” Dedicated button to unmute all tracks at once
- ğŸ”€ **Volume Control** â€” Per-track volume slider for precise mixing
- â¹ï¸ **Reset Position** â€” Jump all tracks back to the start
- ğŸ“ **Markers** â€” Drop up to 3 time markers for quick navigation to specific positions
- â†©ï¸ **Undo / Redo** â€” Full undo/redo history for mute states and markers (Ctrl+Z / Ctrl+Y)
- ğŸ”— **Merge to MP3** â€” Select multiple stems and merge them into a single MP3 track, added as a new layer
- ğŸ“¥ **Download All** â€” Export all separated stems as a ZIP archive with native file picker support
- ğŸ—‘ï¸ **Remove Merged Tracks** â€” Delete merged layers you no longer need
- ğŸ¯ **Drift Correction** â€” Automatic sync correction every 200ms to keep all tracks perfectly aligned

### Waveform Visualization
- ğŸ“ˆ **Real-Time Waveforms** â€” Powered by WaveSurfer.js with color-coded tracks per stem type
- ğŸ–±ï¸ **Click-to-Seek** â€” Click anywhere on any waveform to seek all tracks to that position
- ğŸ“ **Marker Overlays** â€” Visual dashed-line overlays spanning all tracks at marker positions

### UI & UX
- ğŸ¨ **True Black Premium Design** â€” Glassmorphism effects, ambient glow, backdrop blur throughout
- ğŸ“± **Fully Responsive** â€” Calibrated for desktop, tablet, and phone screens
- ğŸšï¸ **Custom Dialogs** â€” No browser `confirm()` or `alert()` â€” all dialogs are styled in-app
- ğŸ’¾ **Session Persistence** â€” Stems saved to IndexedDB so they survive page refreshes
- ğŸ§­ **Drag & Drop Upload** â€” Intuitive file upload with drag-and-drop support and file type validation

### Infrastructure
- ğŸ³ **Production Dockerized** â€” Multi-stage frontend build (Node â†’ Nginx), GPU-accelerated backend
- â˜ï¸ **Cloud-Ready** â€” Optimized for Azure Container Instances and GCP Cloud Run with GPU
- ğŸ” **GitHub CI/CD** â€” Auto-deploy on push via GitHub Actions (no local rebuilds needed)
- ğŸ§¹ **Auto Cleanup** â€” Background thread that periodically cleans up old stems and expired job entries
- ğŸ’š **Health Checks** â€” Both frontend (`/nginx-health`) and backend (`/health`) expose health endpoints

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      User Browser                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ HTTP (port 80)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Frontend Container (Nginx)                   â”‚
â”‚        React 19 Â· Vite Â· Tailwind CSS v4 Â· WaveSurfer     â”‚
â”‚   Serves SPA Â· Proxies /api/* and /stems/* to backend     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ reverse proxy
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Backend Container (FastAPI)                   â”‚
â”‚        Python 3.11 Â· PyTorch Â· Demucs Â· FFmpeg            â”‚
â”‚                                                           â”‚
â”‚   GPU: CUDA â†’ MPS â†’ DirectML â†’ CPU (auto-detect)         â”‚
â”‚   Worker: subprocess-based separation with tqdm parsing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Layer | Technologies |
|-------|-------------|
| **Frontend** | React 19, Vite 7, Tailwind CSS v4, WaveSurfer.js 7, Lucide React, JSZip, lamejs |
| **Backend** | Python 3.11, FastAPI, PyTorch, Demucs (htdemucs_6s), audio-separator, FFmpeg |
| **Infra** | Docker (multi-stage), Nginx, Docker Compose (NVIDIA / CPU / ROCm / Cloud) |

---

## âš¡ GPU Support

| GPU | Backend | OS | Docker | Speed |
|-----|---------|------|--------|-------|
| NVIDIA (CUDA) | `cuda` | Win, Linux | âœ… | âš¡âš¡âš¡ |
| Apple Silicon (MPS) | `mps` | macOS | âŒ Native | âš¡âš¡ |
| AMD (ROCm) | `rocm` | Linux | âœ… | âš¡âš¡ |
| AMD (DirectML) | `directml` | Windows | âŒ Native | âš¡ |
| CPU | `cpu` | All | âœ… | ğŸ¢ |

> **Tip:** Set `DEVICE_OVERRIDE` in `.env` to force a specific device. See [GPU Setup Guide](docs/GPU_SETUP.md).

---

## ğŸš€ Quick Start

### One-Click Install

**Windows:**
```powershell
git clone https://github.com/Shlok-gupta08/unweave.git
cd unweave
powershell -ExecutionPolicy Bypass -File scripts\install.ps1
```

**Linux:**
```bash
git clone https://github.com/Shlok-gupta08/unweave.git
cd unweave
chmod +x scripts/install.sh && ./scripts/install.sh
```

**macOS (Apple Silicon & Intel):**
```bash
git clone https://github.com/Shlok-gupta08/unweave.git
cd unweave
chmod +x scripts/install-mac.sh && ./scripts/install-mac.sh
```

The installer automatically detects your GPU and installs the correct PyTorch build.

### Start the App

```bash
npm run dev
```

- ğŸ¨ **UI:** http://localhost:5173
- ğŸ”§ **API:** http://localhost:8000
- ğŸ’š **Health:** http://localhost:8000/health

---

## âŒ¨ï¸ Keyboard Shortcuts

| Shortcut | Action |
|----------|--------|
| `Ctrl + Z` | Undo (mute state / markers) |
| `Ctrl + Y` / `Ctrl + Shift + Z` | Redo |

---

## ğŸ³ Docker

All containers are production-ready with multi-stage builds and health checks.

```bash
# NVIDIA GPU (default) â€” frontend on port 80, backend on port 8000
docker-compose up --build

# CPU only (no GPU required)
docker-compose -f docker-compose.yml -f docker-compose.cpu.yml up --build

# AMD ROCm (Linux)
docker-compose -f docker-compose.yml -f docker-compose.rocm.yml up --build

# Cloud-optimized (memory limits, logging, restart policies)
docker-compose -f docker-compose.yml -f docker-compose.cloud.yml up --build
```

| Container | Image | Port | Base |
|-----------|-------|------|------|
| Frontend | `unweave-frontend` | 80 | Nginx Alpine (multi-stage build) |
| Backend (CUDA) | `unweave-backend:cuda` | 8000 | NVIDIA CUDA 12.1 + Python 3.11 |
| Backend (CPU) | `unweave-backend:cpu` | 8000 | Python 3.11-slim |
| Backend (ROCm) | `unweave-backend:rocm` | 8000 | ROCm 6.0 |

---

## ğŸ“ Project Structure

```
unweave/
â”œâ”€â”€ frontend/                  # React SPA
â”‚   â”œâ”€â”€ public/                # Static assets (logos, lame.min.js)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/        # UI (Mixer, Track, Uploader, MergeDialog)
â”‚   â”‚   â”œâ”€â”€ utils/             # Audio utilities, IndexedDB helpers
â”‚   â”‚   â”œâ”€â”€ types/             # TypeScript declarations
â”‚   â”‚   â”œâ”€â”€ App.tsx            # Root component with session persistence
â”‚   â”‚   â”œâ”€â”€ main.tsx           # React entry point
â”‚   â”‚   â””â”€â”€ types.ts           # Shared TypeScript interfaces
â”‚   â”œâ”€â”€ Dockerfile             # Multi-stage: Node build â†’ Nginx serve
â”‚   â”œâ”€â”€ nginx.conf             # Nginx config with API reverse proxy
â”‚   â””â”€â”€ .dockerignore
â”œâ”€â”€ backend/                   # FastAPI + AI Engine
â”‚   â”œâ”€â”€ main.py                # API server, GPU detection, job management
â”‚   â”œâ”€â”€ worker.py              # Subprocess worker for stem separation
â”‚   â”œâ”€â”€ Dockerfile             # NVIDIA CUDA 12.1 image
â”‚   â”œâ”€â”€ Dockerfile.cpu         # Lightweight CPU image
â”‚   â”œâ”€â”€ Dockerfile.rocm        # AMD ROCm image
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .dockerignore
â”œâ”€â”€ scripts/                   # One-click installers
â”‚   â”œâ”€â”€ install.ps1            # Windows (PowerShell)
â”‚   â”œâ”€â”€ install.sh             # Linux (Bash)
â”‚   â””â”€â”€ install-mac.sh         # macOS (Bash)
â”œâ”€â”€ docs/                      # Documentation
â”‚   â””â”€â”€ cloud-guide.html       # Interactive cloud deployment guide (HTML)
â”œâ”€â”€ docker-compose.yml         # Default (NVIDIA GPU)
â”œâ”€â”€ docker-compose.cpu.yml     # CPU override
â”œâ”€â”€ docker-compose.rocm.yml    # AMD ROCm override
â”œâ”€â”€ docker-compose.cloud.yml   # Cloud optimization override
â”œâ”€â”€ .env.example               # Environment template
â”œâ”€â”€ CONTRIBUTING.md            # Contribution guide
â””â”€â”€ LICENSE                    # MIT License
```

---

## â˜ï¸ Cloud Deployment

Deploy the backend as a GPU container and frontend as a static Nginx container:

| Platform | Backend | Frontend | Guide |
|----------|---------|----------|-------|
| **Azure** | Container Instances (GPU) | Container Instances (Nginx) | [â†’ Interactive Guide](docs/cloud-guide.html) |
| **GCP** | Cloud Run with GPU | Cloud Run (Nginx) | [â†’ Interactive Guide](docs/cloud-guide.html) |

### GitHub CI/CD

Push to `main` and let GitHub Actions build + deploy automatically â€” no local Docker rebuilds needed. See the [Cloud Guide](docs/cloud-guide.html#github-actions) for workflow YAML templates.

See [Cloud Deployment Guide (HTML)](docs/cloud-guide.html) for full step-by-step instructions with copy-to-clipboard commands, cost estimates, and architecture diagrams.

---

## ğŸ”§ Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `DEVICE_OVERRIDE` | *auto* | Force GPU: `cuda`, `mps`, `directml`, `cpu` |
| `CLOUD_MODE` | `false` | Enable cloud optimizations |
| `MAX_FILE_SIZE_MB` | `50` | Max upload size |
| `CLEANUP_INTERVAL_SECONDS` | `3600` | Stem cleanup interval |
| `WORKERS` | `1` | Uvicorn workers (keep 1 for GPU) |

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [Cloud Guide (Interactive)](docs/cloud-guide.html) | Azure, GCP, GitHub Actions â€” step-by-step |
| [Contributing](CONTRIBUTING.md) | How to contribute |

---

## ğŸ¤ Contributing

Contributions are welcome! See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.
